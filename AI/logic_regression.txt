# 逻辑回归总结
## 主要思想：
用线性回归的输出值（z=WX）经过一个sigmoid函数来映射到（0,1）之间

## 优点：
可以预测与输入对应的类别概率（线性回归做不到）

## 缺点：
因为使用的损失函数是最小化交叉熵损失，所以对离群点很敏感。

## 其他
softmax分类器在神经网络结构中广泛应用于最后一层，因为他会计算出类别概率
## 待解决问题
2. 什么是最小化交叉熵损失？
3. 独热编码？
4. 为什么要对数据标准化处理，如何标准化处理

## 已解决问题
1. 什么叫分类问题？什么叫回归问题？
由最终的输出来决定是什么问题，回归问题的输出是连续值，而分类问题的输出是类别概率。对于输出值为连续值得模型要做分类问题时在最后输出链接sofymax分类器即可。
分类问题和回归问题的目标函数不同，此处依旧存疑。
2.
